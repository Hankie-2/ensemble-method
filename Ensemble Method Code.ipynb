{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09cfdbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectorsl\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85ac246",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = KeyedVectors.load_word2vec_format(\"fasttext.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47f286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = word2vec.KeyedVectors.load_word2vec_format('word2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57081ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_input_file = 'glove.txt'\n",
    "word2vec_output_file = 'glove.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbb7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word, model):\n",
    "    try:\n",
    "        embedding = model[word]\n",
    "        return embedding\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3488e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_word_embedding(word, models):\n",
    "    embeddings = [get_word_embedding(word, model) for model in models]\n",
    "    embeddings = [embedding for embedding in embeddings if embedding is not None]\n",
    "    \n",
    "    if len(embeddings) == 0:\n",
    "        return None\n",
    "    \n",
    "    max_dim = max(embedding.shape[0] for embedding in embeddings)\n",
    "    embeddings = [embedding if embedding.shape[0] == max_dim else np.concatenate((embedding, np.zeros(max_dim - embedding.shape[0])) ) for embedding in embeddings]\n",
    "    \n",
    "    ensemble_embedding = np.mean(embeddings, axis=0)\n",
    "    return ensemble_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69f1f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\myEnv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "models = [w2v_model.wv, glove_model, ft_model.wv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1afab3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'queen':\n",
      "[-2.06146987e-01 -1.25648969e-02 -9.96286472e-02  1.34868383e-01\n",
      "  1.42938649e-01 -2.14799064e-01  1.68100314e-01 -2.79222926e-02\n",
      "  6.51457657e-04 -3.27286450e-02 -2.84494539e-01 -3.90831244e-02\n",
      " -2.03525372e-01  8.09745528e-02  6.54405008e-02  4.14064334e-01\n",
      "  1.46647971e-01  2.30816677e-02 -4.40540089e-02  2.30262753e-01\n",
      "  1.64959895e-01 -1.30604173e-02 -1.10536709e-01  1.03052557e-01\n",
      "  2.13383221e-01 -1.47872182e-02 -7.94125833e-02 -6.50443733e-02\n",
      "  2.55528857e-01  1.09339267e-01  2.35399995e-01 -1.33679794e-01\n",
      "  5.67501535e-02 -4.19431273e-02 -1.79206252e-01 -3.44255308e-01\n",
      "  3.22604689e-02  7.96852907e-02 -7.01098541e-02  3.54079157e-02\n",
      " -3.32888017e-02 -3.51718547e-01  2.25180417e-01 -2.30039991e-01\n",
      "  4.26020833e-02 -9.35498920e-03 -6.77766229e-02  1.53539275e-01\n",
      "  3.62143336e-02 -4.89906222e-02  7.26085529e-02 -2.18465738e-01\n",
      "  1.18742841e-01  9.31000213e-03  6.03480184e-02  1.52554840e-01\n",
      " -1.54846663e-01  5.55794750e-02 -1.68304053e-01  6.01126527e-02\n",
      " -4.24014609e-02  1.62412293e-01  1.03031031e-02 -3.46557274e-02\n",
      " -7.66329120e-02 -4.16508950e-02 -1.25147288e-01  2.15195003e-01\n",
      "  1.00453123e-01 -1.61815892e-01 -2.54239514e-03  2.72612472e-02\n",
      " -2.31404684e-01  1.19601041e-01 -6.52225539e-02  1.08049583e-01\n",
      " -6.52322869e-02  1.28886605e-01  2.92773961e-02  2.66712648e-01\n",
      "  2.17235761e-01  2.64062658e-02  1.35260209e-01  6.88623972e-02\n",
      " -1.45715903e-01  2.67089593e-02 -1.48773336e-01  2.97349470e-01\n",
      "  1.77117292e-01 -1.16341558e-01  1.04751167e-01 -2.47355408e-01\n",
      " -8.53233337e-02 -1.44112837e-01  9.49116033e-02 -2.14653539e-01\n",
      "  3.80937407e-02 -3.10731741e-03  4.37107501e-02 -5.58979710e-02\n",
      " -2.21187279e-01  7.67674992e-02 -1.54588848e-01 -1.79900837e-01\n",
      " -2.54761662e-01 -3.08444295e-02 -7.46662480e-02 -1.81357180e-01\n",
      "  5.79788443e-03  1.44870006e-01  9.05850833e-02  2.70525513e-01\n",
      "  1.54930003e-01 -1.64458337e-01 -5.55271034e-03 -9.39045809e-02\n",
      "  7.29965044e-02 -6.08550006e-02  1.75021666e-01  8.79750843e-02\n",
      "  1.27354583e-01  6.17131243e-02  1.33537327e-01  8.24177576e-03\n",
      "  1.45592811e-01  1.45496063e-01  1.29823618e-01 -2.82818762e-02\n",
      "  9.28950806e-02  1.65833598e-01  1.68970885e-01  1.10874689e-01\n",
      "  1.09186480e-01  1.25742082e-01  2.72995333e-01  1.53963226e-01\n",
      " -1.64558490e-05 -6.27034431e-02  3.17461036e-01  3.24781972e-02\n",
      " -1.76942403e-01  2.55322930e-02  1.08804191e-01 -1.64031306e-01\n",
      "  1.12409949e-01  1.63952110e-01 -1.38906459e-01  4.66238124e-02\n",
      " -1.54923127e-01  1.90735747e-01 -1.40599402e-01  1.18144063e-01\n",
      " -1.19442786e+00 -1.90564586e-01 -1.71932603e-01  3.82272899e-02\n",
      " -1.99540963e-01  1.53849088e-01 -4.41094786e-02 -1.16185421e-01\n",
      "  1.60805682e-01 -7.67698990e-02  6.08754158e-02 -2.32177794e-01\n",
      "  1.24540676e-01 -1.29727862e-01  1.12707814e-01 -1.22536041e-01\n",
      "  1.14747820e-02  2.44236045e-01  2.81867714e-02 -1.32581037e-01\n",
      "  5.27323323e-02 -2.27891306e-02 -7.21108119e-02  1.18368765e-02\n",
      " -2.93237027e-02 -8.59099130e-03 -1.67397711e-01  3.96877006e-02\n",
      "  2.06498951e-02  8.19317708e-02  1.46810419e-01  1.62516405e-01\n",
      "  3.22051036e-02  4.64990127e-02  1.30622602e-01  1.05928589e-01\n",
      " -6.83188836e-02  3.72702101e-02  5.42618955e-02 -6.44827113e-02\n",
      "  2.36061454e-01 -1.11144267e-01  3.17150839e-02 -9.16109337e-02\n",
      "  1.83860415e-01  8.80496980e-03 -1.20836000e-04 -3.29677284e-01\n",
      "  4.15349131e-03 -1.19231765e-02 -1.08045707e-01 -3.65864585e-02\n",
      "  4.16649083e-02 -7.23947907e-02  5.62739583e-02  1.26489585e-01\n",
      "  8.46145824e-02  8.34463543e-02  2.01466146e-02  1.86236979e-02\n",
      " -5.70570305e-02 -8.62375000e-02  1.92348957e-02 -1.37894700e-02\n",
      " -6.64057285e-02 -7.58302084e-02  6.90348968e-02  5.29606777e-02\n",
      " -7.88020839e-03  1.33574220e-02  7.27791662e-02 -4.07374681e-03\n",
      " -3.56613944e-02 -3.98207108e-02  6.85333336e-02 -1.12271875e-01\n",
      "  8.61067822e-03  2.61572897e-02 -9.14197918e-02 -1.05003125e-01\n",
      " -1.28167708e-01  3.89229168e-02  1.41461458e-01 -1.45513018e-02\n",
      "  3.76957009e-02  2.20411470e-02 -1.42009072e-02 -2.90781247e-02\n",
      "  1.14451041e-01 -8.62520834e-02 -5.41926920e-03 -3.98844406e-02\n",
      "  8.52401033e-02 -4.66308556e-04 -1.55057286e-02 -3.18619857e-03\n",
      "  4.55697918e-02 -4.21640625e-02  2.34382811e-02 -1.62365076e-02\n",
      "  6.72255208e-02  7.86197918e-02  3.29041667e-02  2.83570314e-02\n",
      " -1.64898957e-01 -5.60653657e-02 -1.47307292e-01 -2.63986985e-02\n",
      "  2.53223957e-02  1.02072917e-01 -1.28380209e-01 -3.35791667e-02\n",
      " -2.05201823e-02  4.68786458e-02  2.93631516e-02  1.48624999e-01\n",
      "  8.17479168e-02  9.27416667e-02 -1.22845834e-01  9.02838546e-02\n",
      "  1.07526034e-02  2.96635417e-02  5.97000001e-02 -1.32477082e-01\n",
      "  4.42557291e-02 -2.34109374e-02 -6.23802096e-02  8.19812504e-02\n",
      "  1.18328134e-02  5.71536521e-03  6.17406244e-02 -3.80675793e-02\n",
      "  6.04270833e-02 -3.58078132e-02 -2.09783850e-02 -5.56265625e-02\n",
      " -5.67065428e-03  6.62692711e-02 -2.55027190e-02 -1.00828645e-01\n",
      " -1.93702082e-01 -1.30617708e-01 -4.71731772e-02  1.80467442e-02\n",
      "  4.05562495e-02  3.47749988e-02  6.56619792e-02  6.06656248e-02]\n"
     ]
    }
   ],
   "source": [
    "word = \"queen\"\n",
    "embedding = ensemble_word_embedding(word, models)\n",
    "if embedding is not None:\n",
    "    print(f\"Embedding for '{word}':\")\n",
    "    print(embedding)\n",
    "else:\n",
    "    print(f\"No embedding found for '{word}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "377fe477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between 'queen' and 'king':\n",
      "Cosine similarity: 0.6888364900233708\n",
      "Comparison between 'queen' and 'princess':\n",
      "Cosine similarity: 0.7175951708973198\n"
     ]
    }
   ],
   "source": [
    "def compare_vectors_cosine_similarity(vector1, vector2):\n",
    "    similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    return similarity\n",
    "\n",
    "compare_word1 = \"king\"\n",
    "compare_word2 = \"princess\"\n",
    "\n",
    "compare_embedding1 = ensemble_word_embedding(compare_word1, models)\n",
    "compare_embedding2 = ensemble_word_embedding(compare_word2, models)\n",
    "\n",
    "if compare_embedding1 is not None and compare_embedding2 is not None:\n",
    "    print(f\"Comparison between '{word}' and '{compare_word1}':\")\n",
    "    similarity1 = compare_vectors_cosine_similarity(embedding, compare_embedding1)\n",
    "    print(f\"Cosine similarity: {similarity1}\")\n",
    "\n",
    "    print(f\"Comparison between '{word}' and '{compare_word2}':\")\n",
    "    similarity2 = compare_vectors_cosine_similarity(embedding, compare_embedding2)\n",
    "    print(f\"Cosine similarity: {similarity2}\")\n",
    "else:\n",
    "    print(\"No comparison can be made due to missing embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "472d2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between 'queen' and 'car':\n",
      "Cosine similarity: 0.282770693820894\n",
      "Comparison between 'queen' and 'laptop':\n",
      "Cosine similarity: 0.17996554165373016\n"
     ]
    }
   ],
   "source": [
    "def compare_vectors_cosine_similarity(vector1, vector2):\n",
    "    similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    return similarity\n",
    "\n",
    "compare_word1 = \"car\"\n",
    "compare_word2 = \"laptop\"\n",
    "\n",
    "compare_embedding1 = ensemble_word_embedding(compare_word1, models)\n",
    "compare_embedding2 = ensemble_word_embedding(compare_word2, models)\n",
    "\n",
    "if compare_embedding1 is not None and compare_embedding2 is not None:\n",
    "    print(f\"Comparison between '{word}' and '{compare_word1}':\")\n",
    "    similarity1 = compare_vectors_cosine_similarity(embedding, compare_embedding1)\n",
    "    print(f\"Cosine similarity: {similarity1}\")\n",
    "\n",
    "    print(f\"Comparison between '{word}' and '{compare_word2}':\")\n",
    "    similarity2 = compare_vectors_cosine_similarity(embedding, compare_embedding2)\n",
    "    print(f\"Cosine similarity: {similarity2}\")\n",
    "else:\n",
    "    print(\"No comparison can be made due to missing embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb62a85",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4adaf08",
   "metadata": {},
   "source": [
    "### Pre-Trained Word vectors were downloaded from the site https://developer.syn.co.in/tutorial/bot/oscova/pretrained-vectors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce864f3c",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
